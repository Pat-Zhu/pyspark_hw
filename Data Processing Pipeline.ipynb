{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Using incubator modules: jdk.incubator.vector\n",
      "Using Spark's default log4j profile: org/apache/spark/log4j2-defaults.properties\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "25/11/10 15:54:58 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+\n",
      "| id|\n",
      "+---+\n",
      "|  0|\n",
      "|  1|\n",
      "|  2|\n",
      "|  3|\n",
      "|  4|\n",
      "|  5|\n",
      "|  6|\n",
      "|  7|\n",
      "|  8|\n",
      "|  9|\n",
      "+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "spark = (SparkSession.builder.appName(\"VSCodeTest\")\n",
    "         .master(\"local[*]\")\n",
    "         .config(\"spark.sql.adaptive.enabled\",\"true\").getOrCreate())\n",
    "spark.sparkContext.setLogLevel(\"ERROR\")\n",
    "spark.range(10).show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col, lit\n",
    "from pyspark.sql import DataFrame\n",
    "\n",
    "CANONICAL_TYPES = {\n",
    "    \"VendorID\": \"int\",\n",
    "    \"tpep_pickup_datetime\": \"timestamp\",\n",
    "    \"tpep_dropoff_datetime\": \"timestamp\",\n",
    "    \"passenger_count\": \"int\",\n",
    "    \"trip_distance\": \"double\",\n",
    "    \"RatecodeID\": \"int\",\n",
    "    \"store_and_fwd_flag\": \"string\",\n",
    "    \"PULocationID\": \"int\",\n",
    "    \"DOLocationID\": \"int\",\n",
    "    \"payment_type\": \"int\",\n",
    "    \"fare_amount\": \"double\",\n",
    "    \"extra\": \"double\",\n",
    "    \"mta_tax\": \"double\",\n",
    "    \"tip_amount\": \"double\",\n",
    "    \"tolls_amount\": \"double\",\n",
    "    \"improvement_surcharge\": \"double\",\n",
    "    \"total_amount\": \"double\",\n",
    "    \"congestion_surcharge\": \"double\",\n",
    "    \"airport_fee\": \"double\",  \n",
    "}\n",
    "\n",
    "def normalize_columns(df: DataFrame) -> DataFrame:\n",
    "    if \"Airport_fee\" in df.columns and \"airport_fee\" not in df.columns:\n",
    "        df = df.withColumnRenamed(\"Airport_fee\", \"airport_fee\")\n",
    "\n",
    "    for c, t in CANONICAL_TYPES.items():\n",
    "        if c not in df.columns:\n",
    "            df = df.withColumn(c, lit(None).cast(t))\n",
    "\n",
    "    for c, t in CANONICAL_TYPES.items():\n",
    "        if c in df.columns:\n",
    "            df = df.withColumn(c, col(c).cast(t))\n",
    "\n",
    "    return df.select(*CANONICAL_TYPES.keys())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "try:\n",
    "    spark.stop()\n",
    "except:\n",
    "    pass\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = (\n",
    "    SparkSession.builder\n",
    "    .appName(\"NYCTaxi-ETL\")\n",
    "    .master(\"local[*]\")                           \n",
    "    .config(\"spark.driver.memory\", \"8g\")          \n",
    "    .config(\"spark.sql.adaptive.enabled\", \"true\") \n",
    "    .config(\"spark.sql.shuffle.partitions\", \"24\") \n",
    "    .config(\"spark.sql.files.maxPartitionBytes\", \"32m\")  \n",
    "    .config(\"spark.serializer\", \"org.apache.spark.serializer.KryoSerializer\")\n",
    "    .getOrCreate()\n",
    ")\n",
    "spark.sparkContext.setLogLevel(\"ERROR\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col, lit\n",
    "from pyspark.sql import DataFrame\n",
    "\n",
    "CANONICAL_TYPES = {\n",
    "    \"VendorID\": \"int\",\n",
    "    \"tpep_pickup_datetime\": \"timestamp\",\n",
    "    \"tpep_dropoff_datetime\": \"timestamp\",\n",
    "    \"passenger_count\": \"int\",\n",
    "    \"trip_distance\": \"double\",\n",
    "    \"RatecodeID\": \"int\",\n",
    "    \"store_and_fwd_flag\": \"string\",\n",
    "    \"PULocationID\": \"int\",\n",
    "    \"DOLocationID\": \"int\",\n",
    "    \"payment_type\": \"int\",\n",
    "    \"fare_amount\": \"double\",\n",
    "    \"extra\": \"double\",\n",
    "    \"mta_tax\": \"double\",\n",
    "    \"tip_amount\": \"double\",\n",
    "    \"tolls_amount\": \"double\",\n",
    "    \"improvement_surcharge\": \"double\",\n",
    "    \"total_amount\": \"double\",\n",
    "    \"congestion_surcharge\": \"double\",\n",
    "    \"airport_fee\": \"double\",\n",
    "}\n",
    "\n",
    "def normalize_columns(df: DataFrame) -> DataFrame:\n",
    "    if \"Airport_fee\" in df.columns and \"airport_fee\" not in df.columns:\n",
    "        df = df.withColumnRenamed(\"Airport_fee\", \"airport_fee\")\n",
    "    for c, t in CANONICAL_TYPES.items():\n",
    "        if c not in df.columns:\n",
    "            df = df.withColumn(c, lit(None).cast(t))\n",
    "    for c, t in CANONICAL_TYPES.items():\n",
    "        if c in df.columns:\n",
    "            df = df.withColumn(c, col(c).cast(t))\n",
    "    return df.select(*CANONICAL_TYPES.keys())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import to_timestamp, expr, date_format\n",
    "\n",
    "def etl_and_write_one(path: str, out_path: str):\n",
    "    df = normalize_columns(spark.read.parquet(path))\n",
    "\n",
    "    df2 = (\n",
    "        df\n",
    "        .withColumn(\"pickup_ts\",  to_timestamp(col(\"tpep_pickup_datetime\")))\n",
    "        .withColumn(\"dropoff_ts\", to_timestamp(col(\"tpep_dropoff_datetime\")))\n",
    "        .withColumn(\"trip_minutes\", expr(\"timestampdiff(MINUTE, pickup_ts, dropoff_ts)\"))\n",
    "        .filter((col(\"trip_distance\") > 0) & (col(\"fare_amount\") > 0))\n",
    "        .filter((col(\"trip_minutes\") > 0) & (col(\"trip_minutes\") < 360))\n",
    "        .withColumn(\"year\",  date_format(col(\"pickup_ts\"), \"yyyy\"))\n",
    "        .withColumn(\"month\", date_format(col(\"pickup_ts\"), \"MM\"))\n",
    "        .select(\n",
    "            \"pickup_ts\",\"dropoff_ts\",\"trip_minutes\",\"passenger_count\",\"trip_distance\",\n",
    "            \"payment_type\",\"fare_amount\",\"tip_amount\",\"tolls_amount\",\"improvement_surcharge\",\n",
    "            \"total_amount\",\"congestion_surcharge\",\"airport_fee\",\"PULocationID\",\"DOLocationID\",\n",
    "            \"year\",\"month\"\n",
    "        )\n",
    "    )\n",
    "\n",
    "    (df2\n",
    "     .repartition(4, \"year\", \"month\")       \n",
    "     .write.mode(\"append\")\n",
    "     .option(\"compression\",\"snappy\")\n",
    "     .partitionBy(\"year\",\"month\")\n",
    "     .parquet(out_path))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>> processing: ../data/raw/yellow_tripdata_2019-01.parquet\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>> processing: ../data/raw/yellow_tripdata_2019-02.parquet\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>> processing: ../data/raw/yellow_tripdata_2019-03.parquet\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>> processing: ../data/raw/yellow_tripdata_2019-04.parquet\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>> processing: ../data/raw/yellow_tripdata_2019-05.parquet\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>> processing: ../data/raw/yellow_tripdata_2019-06.parquet\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>> processing: ../data/raw/yellow_tripdata_2019-07.parquet\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>> processing: ../data/raw/yellow_tripdata_2019-08.parquet\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>> processing: ../data/raw/yellow_tripdata_2019-09.parquet\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>> processing: ../data/raw/yellow_tripdata_2019-10.parquet\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>> processing: ../data/raw/yellow_tripdata_2019-11.parquet\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>> processing: ../data/raw/yellow_tripdata_2019-12.parquet\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>> processing: ../data/raw/yellow_tripdata_2024-01.parquet\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>> processing: ../data/raw/yellow_tripdata_2024-02.parquet\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>> processing: ../data/raw/yellow_tripdata_2024-03.parquet\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 59:===========================================>              (3 + 1) / 4]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ All files processed and written to ../data/processed/yellow_bronze.parquet\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "\n",
    "raw_2019 = sorted(glob.glob(\"../data/raw/yellow_tripdata_2019-*.parquet\"))\n",
    "raw_2024 = sorted(glob.glob(\"../data/raw/yellow_tripdata_2024-*.parquet\"))\n",
    "raw_paths = raw_2019 + raw_2024\n",
    "\n",
    "out_path = \"../data/processed/yellow_bronze.parquet\"\n",
    "\n",
    "for p in raw_paths:\n",
    "    print(\">>> processing:\", p)\n",
    "    etl_and_write_one(p, out_path)\n",
    "\n",
    "print(\"✅ All files processed and written to\", out_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- pickup_ts: timestamp (nullable = true)\n",
      " |-- dropoff_ts: timestamp (nullable = true)\n",
      " |-- trip_minutes: long (nullable = true)\n",
      " |-- passenger_count: integer (nullable = true)\n",
      " |-- trip_distance: double (nullable = true)\n",
      " |-- payment_type: integer (nullable = true)\n",
      " |-- fare_amount: double (nullable = true)\n",
      " |-- tip_amount: double (nullable = true)\n",
      " |-- tolls_amount: double (nullable = true)\n",
      " |-- improvement_surcharge: double (nullable = true)\n",
      " |-- total_amount: double (nullable = true)\n",
      " |-- congestion_surcharge: double (nullable = true)\n",
      " |-- airport_fee: double (nullable = true)\n",
      " |-- PULocationID: integer (nullable = true)\n",
      " |-- DOLocationID: integer (nullable = true)\n",
      " |-- year: integer (nullable = true)\n",
      " |-- month: integer (nullable = true)\n",
      "\n",
      "+-------------------+-------------------+------------+---------------+-------------+------------+-----------+----------+------------+---------------------+------------+--------------------+-----------+------------+------------+----+-----+\n",
      "|pickup_ts          |dropoff_ts         |trip_minutes|passenger_count|trip_distance|payment_type|fare_amount|tip_amount|tolls_amount|improvement_surcharge|total_amount|congestion_surcharge|airport_fee|PULocationID|DOLocationID|year|month|\n",
      "+-------------------+-------------------+------------+---------------+-------------+------------+-----------+----------+------------+---------------------+------------+--------------------+-----------+------------+------------+----+-----+\n",
      "|2019-04-01 00:04:09|2019-04-01 00:06:35|2           |1              |0.5          |1           |4.0        |1.0       |0.0         |0.3                  |8.8         |2.5                 |NULL       |239         |239         |2019|4    |\n",
      "|2019-04-29 21:42:15|2019-04-29 21:46:15|4           |1              |0.79         |1           |65.0       |14.88     |6.12        |0.3                  |89.3        |2.5                 |NULL       |170         |100         |2019|4    |\n",
      "|2019-04-01 00:22:45|2019-04-01 00:25:43|2           |1              |0.7          |2           |4.5        |0.0       |0.0         |0.3                  |8.3         |2.5                 |NULL       |230         |100         |2019|4    |\n",
      "|2019-04-29 21:49:48|2019-04-29 22:03:44|13          |1              |2.14         |2           |11.0       |0.0       |0.0         |0.3                  |14.8        |2.5                 |NULL       |100         |114         |2019|4    |\n",
      "|2019-04-01 00:39:48|2019-04-01 01:19:39|39          |1              |10.9         |1           |36.0       |7.95      |0.0         |0.3                  |47.75       |2.5                 |NULL       |68          |127         |2019|4    |\n",
      "+-------------------+-------------------+------------+---------------+-------------+------------+-----------+----------+------------+---------------------+------------+--------------------+-----------+------------+------------+----+-----+\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "7584818"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bronze = spark.read.parquet(\"../data/processed/yellow_bronze.parquet\")\n",
    "bronze.printSchema()\n",
    "bronze.limit(5).show(truncate=False)\n",
    "\n",
    "\n",
    "from pyspark.sql.functions import col\n",
    "jan2019 = bronze.filter((col(\"year\")==\"2019\") & (col(\"month\")==\"01\"))\n",
    "jan2019.count()  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = (\n",
    "    SparkSession.builder\n",
    "    .appName(\"NYCTaxi-Big\")\n",
    "    .master(\"local[*]\")\n",
    "    .config(\"spark.driver.memory\", \"6g\")          \n",
    "    .config(\"spark.sql.adaptive.enabled\", \"true\") \n",
    "    .config(\"spark.sql.shuffle.partitions\", \"48\") \n",
    "    .config(\"spark.sql.files.maxPartitionBytes\", \"64m\") \n",
    "    .getOrCreate()\n",
    ")\n",
    "spark.sparkContext.setLogLevel(\"ERROR\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pipeline Starts here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "UI: http://patricks-air-4.lan:4040\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    spark.stop()\n",
    "except:\n",
    "    pass\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = (\n",
    "    SparkSession.builder\n",
    "    .appName(\"NYCTaxi-PIPELINE\")\n",
    "    .master(\"local[*]\")\n",
    "    .config(\"spark.driver.memory\", \"8g\")          \n",
    "    .config(\"spark.sql.adaptive.enabled\", \"true\") \n",
    "    .config(\"spark.sql.shuffle.partitions\", \"24\") \n",
    "    .config(\"spark.sql.files.maxPartitionBytes\", \"32m\")  \n",
    "    .config(\"spark.serializer\", \"org.apache.spark.serializer.KryoSerializer\")\n",
    "    .getOrCreate()\n",
    ")\n",
    "spark.sparkContext.setLogLevel(\"ERROR\")\n",
    "print(\"UI:\", spark.sparkContext.uiWebUrl)  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+----------+------------+---------------+-------------+------------+-----------+----------+------------+---------------------+------------+--------------------+-----------+------------+------------+----+-----+\n",
      "|pickup_ts|dropoff_ts|trip_minutes|passenger_count|trip_distance|payment_type|fare_amount|tip_amount|tolls_amount|improvement_surcharge|total_amount|congestion_surcharge|airport_fee|PULocationID|DOLocationID|year|month|\n",
      "+---------+----------+------------+---------------+-------------+------------+-----------+----------+------------+---------------------+------------+--------------------+-----------+------------+------------+----+-----+\n",
      "+---------+----------+------------+---------------+-------------+------------+-----------+----------+------------+---------------------+------------+--------------------+-----------+------------+------------+----+-----+\n",
      "\n",
      "== Physical Plan ==\n",
      "* ColumnarToRow (2)\n",
      "+- Scan parquet  (1)\n",
      "\n",
      "\n",
      "(1) Scan parquet \n",
      "Output [17]: [pickup_ts#2960, dropoff_ts#2961, trip_minutes#2962L, passenger_count#2963, trip_distance#2964, payment_type#2965, fare_amount#2966, tip_amount#2967, tolls_amount#2968, improvement_surcharge#2969, total_amount#2970, congestion_surcharge#2971, airport_fee#2972, PULocationID#2973, DOLocationID#2974, year#2975, month#2976]\n",
      "Batched: true\n",
      "Location: InMemoryFileIndex [file:/Users/patrickzhu/Desktop/pyspark_pipeline_project/data/processed/yellow_bronze.parquet]\n",
      "PartitionFilters: [cast(year#2975 as string) IN (2019,2024), cast(month#2976 as string) IN (01,02,03)]\n",
      "ReadSchema: struct<pickup_ts:timestamp,dropoff_ts:timestamp,trip_minutes:bigint,passenger_count:int,trip_distance:double,payment_type:int,fare_amount:double,tip_amount:double,tolls_amount:double,improvement_surcharge:double,total_amount:double,congestion_surcharge:double,airport_fee:double,PULocationID:int,DOLocationID:int>\n",
      "\n",
      "(2) ColumnarToRow [codegen id : 1]\n",
      "Input [17]: [pickup_ts#2960, dropoff_ts#2961, trip_minutes#2962L, passenger_count#2963, trip_distance#2964, payment_type#2965, fare_amount#2966, tip_amount#2967, tolls_amount#2968, improvement_surcharge#2969, total_amount#2970, congestion_surcharge#2971, airport_fee#2972, PULocationID#2973, DOLocationID#2974, year#2975, month#2976]\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import col\n",
    "\n",
    "bronze_path = \"../data/processed/yellow_bronze.parquet\"\n",
    "\n",
    "bronze = (\n",
    "    spark.read.parquet(bronze_path)\n",
    "    .where(col(\"year\").cast(\"string\").isin(\"2019\",\"2024\"))\n",
    "    .where(col(\"month\").cast(\"string\").isin(\"01\",\"02\",\"03\"))\n",
    "    .select(\n",
    "\n",
    "        \"pickup_ts\",\"dropoff_ts\",\"trip_minutes\",\"passenger_count\",\"trip_distance\",\n",
    "        \"payment_type\",\"fare_amount\",\"tip_amount\",\"tolls_amount\",\"improvement_surcharge\",\n",
    "        \"total_amount\",\"congestion_surcharge\",\"airport_fee\",\"PULocationID\",\"DOLocationID\",\n",
    "        \"year\",\"month\"\n",
    "    )\n",
    ")\n",
    "\n",
    "bronze.limit(5).show(truncate=False)\n",
    "bronze.explain(\"formatted\")   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+----------+------------+---------------+-------------+------------+-----------+----------+------------+---------------------+------------+--------------------+-----------+------------+------------+----+-----+----------+-------+--------+\n",
      "|pickup_ts|dropoff_ts|trip_minutes|passenger_count|trip_distance|payment_type|fare_amount|tip_amount|tolls_amount|improvement_surcharge|total_amount|congestion_surcharge|airport_fee|PULocationID|DOLocationID|year|month|trip_hours|avg_mph|tip_rate|\n",
      "+---------+----------+------------+---------------+-------------+------------+-----------+----------+------------+---------------------+------------+--------------------+-----------+------------+------------+----+-----+----------+-------+--------+\n",
      "+---------+----------+------------+---------------+-------------+------------+-----------+----------+------------+---------------------+------------+--------------------+-----------+------------+------------+----+-----+----------+-------+--------+\n",
      "\n",
      "== Physical Plan ==\n",
      "* Project (5)\n",
      "+- * Project (4)\n",
      "   +- * Filter (3)\n",
      "      +- * ColumnarToRow (2)\n",
      "         +- Scan parquet  (1)\n",
      "\n",
      "\n",
      "(1) Scan parquet \n",
      "Output [17]: [pickup_ts#2960, dropoff_ts#2961, trip_minutes#2962L, passenger_count#2963, trip_distance#2964, payment_type#2965, fare_amount#2966, tip_amount#2967, tolls_amount#2968, improvement_surcharge#2969, total_amount#2970, congestion_surcharge#2971, airport_fee#2972, PULocationID#2973, DOLocationID#2974, year#2975, month#2976]\n",
      "Batched: true\n",
      "Location: InMemoryFileIndex [file:/Users/patrickzhu/Desktop/pyspark_pipeline_project/data/processed/yellow_bronze.parquet]\n",
      "PartitionFilters: [cast(year#2975 as string) IN (2019,2024), cast(month#2976 as string) IN (01,02,03)]\n",
      "PushedFilters: [IsNotNull(trip_distance), IsNotNull(fare_amount), IsNotNull(trip_minutes), IsNotNull(passenger_count), GreaterThan(trip_distance,0.0), GreaterThan(fare_amount,0.0), GreaterThan(trip_minutes,0), LessThan(trip_minutes,360), GreaterThanOrEqual(passenger_count,1), LessThanOrEqual(passenger_count,6)]\n",
      "ReadSchema: struct<pickup_ts:timestamp,dropoff_ts:timestamp,trip_minutes:bigint,passenger_count:int,trip_distance:double,payment_type:int,fare_amount:double,tip_amount:double,tolls_amount:double,improvement_surcharge:double,total_amount:double,congestion_surcharge:double,airport_fee:double,PULocationID:int,DOLocationID:int>\n",
      "\n",
      "(2) ColumnarToRow [codegen id : 1]\n",
      "Input [17]: [pickup_ts#2960, dropoff_ts#2961, trip_minutes#2962L, passenger_count#2963, trip_distance#2964, payment_type#2965, fare_amount#2966, tip_amount#2967, tolls_amount#2968, improvement_surcharge#2969, total_amount#2970, congestion_surcharge#2971, airport_fee#2972, PULocationID#2973, DOLocationID#2974, year#2975, month#2976]\n",
      "\n",
      "(3) Filter [codegen id : 1]\n",
      "Input [17]: [pickup_ts#2960, dropoff_ts#2961, trip_minutes#2962L, passenger_count#2963, trip_distance#2964, payment_type#2965, fare_amount#2966, tip_amount#2967, tolls_amount#2968, improvement_surcharge#2969, total_amount#2970, congestion_surcharge#2971, airport_fee#2972, PULocationID#2973, DOLocationID#2974, year#2975, month#2976]\n",
      "Condition : (((((((((((isnotnull(trip_distance#2964) AND isnotnull(fare_amount#2966)) AND isnotnull(trip_minutes#2962L)) AND isnotnull(passenger_count#2963)) AND (trip_distance#2964 > 0.0)) AND (fare_amount#2966 > 0.0)) AND (trip_minutes#2962L > 0)) AND (trip_minutes#2962L < 360)) AND (passenger_count#2963 >= 1)) AND (passenger_count#2963 <= 6)) AND CASE WHEN ((cast(trip_minutes#2962L as double) / 60.0) > 0.0) THEN ((trip_distance#2964 / (cast(trip_minutes#2962L as double) / 60.0)) >= 1.0) END) AND CASE WHEN ((cast(trip_minutes#2962L as double) / 60.0) > 0.0) THEN ((trip_distance#2964 / (cast(trip_minutes#2962L as double) / 60.0)) <= 80.0) END)\n",
      "\n",
      "(4) Project [codegen id : 1]\n",
      "Output [18]: [pickup_ts#2960, dropoff_ts#2961, trip_minutes#2962L, passenger_count#2963, trip_distance#2964, payment_type#2965, fare_amount#2966, tip_amount#2967, tolls_amount#2968, improvement_surcharge#2969, total_amount#2970, congestion_surcharge#2971, airport_fee#2972, PULocationID#2973, DOLocationID#2974, year#2975, month#2976, (cast(trip_minutes#2962L as double) / 60.0) AS trip_hours#3030]\n",
      "Input [17]: [pickup_ts#2960, dropoff_ts#2961, trip_minutes#2962L, passenger_count#2963, trip_distance#2964, payment_type#2965, fare_amount#2966, tip_amount#2967, tolls_amount#2968, improvement_surcharge#2969, total_amount#2970, congestion_surcharge#2971, airport_fee#2972, PULocationID#2973, DOLocationID#2974, year#2975, month#2976]\n",
      "\n",
      "(5) Project [codegen id : 1]\n",
      "Output [20]: [pickup_ts#2960, dropoff_ts#2961, trip_minutes#2962L, passenger_count#2963, trip_distance#2964, payment_type#2965, fare_amount#2966, tip_amount#2967, tolls_amount#2968, improvement_surcharge#2969, total_amount#2970, congestion_surcharge#2971, airport_fee#2972, PULocationID#2973, DOLocationID#2974, year#2975, month#2976, trip_hours#3030, CASE WHEN (trip_hours#3030 > 0.0) THEN (trip_distance#2964 / trip_hours#3030) END AS avg_mph#3031, CASE WHEN (fare_amount#2966 > 0.0) THEN (tip_amount#2967 / fare_amount#2966) END AS tip_rate#3032]\n",
      "Input [18]: [pickup_ts#2960, dropoff_ts#2961, trip_minutes#2962L, passenger_count#2963, trip_distance#2964, payment_type#2965, fare_amount#2966, tip_amount#2967, tolls_amount#2968, improvement_surcharge#2969, total_amount#2970, congestion_surcharge#2971, airport_fee#2972, PULocationID#2973, DOLocationID#2974, year#2975, month#2976, trip_hours#3030]\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import when\n",
    "\n",
    "df = (\n",
    "    bronze\n",
    "    .withColumn(\"trip_hours\",  (col(\"trip_minutes\")/60.0))\n",
    "    .withColumn(\"avg_mph\",     when(col(\"trip_hours\") > 0, col(\"trip_distance\")/col(\"trip_hours\")).otherwise(None))\n",
    "    .withColumn(\"tip_rate\",    when(col(\"fare_amount\") > 0, col(\"tip_amount\")/col(\"fare_amount\")).otherwise(None))\n",
    ")\n",
    "\n",
    "df_f = (\n",
    "    df\n",
    "\n",
    "    .filter((col(\"trip_distance\") > 0) & (col(\"fare_amount\") > 0))\n",
    "    .filter((col(\"trip_minutes\")  > 0) & (col(\"trip_minutes\") < 360))\n",
    "    .filter((col(\"passenger_count\") >= 1) & (col(\"passenger_count\") <= 6))\n",
    "    .filter((col(\"avg_mph\") >= 1) & (col(\"avg_mph\") <= 80))\n",
    ")\n",
    "\n",
    "df_f.limit(5).show(truncate=False)\n",
    "df_f.explain(\"formatted\")   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+----------+------------+---------------+-------------+------------+-----------+----------+------------+---------------------+------------+--------------------+-----------+------------+------------+----+-----+----------+-------+--------+\n",
      "|pickup_ts|dropoff_ts|trip_minutes|passenger_count|trip_distance|payment_type|fare_amount|tip_amount|tolls_amount|improvement_surcharge|total_amount|congestion_surcharge|airport_fee|PULocationID|DOLocationID|year|month|trip_hours|avg_mph|tip_rate|\n",
      "+---------+----------+------------+---------------+-------------+------------+-----------+----------+------------+---------------------+------------+--------------------+-----------+------------+------------+----+-----+----------+-------+--------+\n",
      "+---------+----------+------------+---------------+-------------+------------+-----------+----------+------------+---------------------+------------+--------------------+-----------+------------+------------+----+-----+----------+-------+--------+\n",
      "\n",
      "== Physical Plan ==\n",
      "* Project (5)\n",
      "+- * Project (4)\n",
      "   +- * Filter (3)\n",
      "      +- * ColumnarToRow (2)\n",
      "         +- Scan parquet  (1)\n",
      "\n",
      "\n",
      "(1) Scan parquet \n",
      "Output [17]: [pickup_ts#3095, dropoff_ts#3096, trip_minutes#3097L, passenger_count#3098, trip_distance#3099, payment_type#3100, fare_amount#3101, tip_amount#3102, tolls_amount#3103, improvement_surcharge#3104, total_amount#3105, congestion_surcharge#3106, airport_fee#3107, PULocationID#3108, DOLocationID#3109, year#3110, month#3111]\n",
      "Batched: true\n",
      "Location: InMemoryFileIndex [file:/Users/patrickzhu/Desktop/pyspark_pipeline_project/data/processed/yellow_bronze.parquet]\n",
      "PartitionFilters: [cast(year#3110 as string) IN (2019,2024), cast(month#3111 as string) IN (01,02,03)]\n",
      "PushedFilters: [IsNotNull(trip_distance), IsNotNull(fare_amount), IsNotNull(trip_minutes), IsNotNull(passenger_count), GreaterThan(trip_distance,0.0), GreaterThan(fare_amount,0.0), GreaterThan(trip_minutes,0), LessThan(trip_minutes,360), GreaterThanOrEqual(passenger_count,1), LessThanOrEqual(passenger_count,6)]\n",
      "ReadSchema: struct<pickup_ts:timestamp,dropoff_ts:timestamp,trip_minutes:bigint,passenger_count:int,trip_distance:double,payment_type:int,fare_amount:double,tip_amount:double,tolls_amount:double,improvement_surcharge:double,total_amount:double,congestion_surcharge:double,airport_fee:double,PULocationID:int,DOLocationID:int>\n",
      "\n",
      "(2) ColumnarToRow [codegen id : 1]\n",
      "Input [17]: [pickup_ts#3095, dropoff_ts#3096, trip_minutes#3097L, passenger_count#3098, trip_distance#3099, payment_type#3100, fare_amount#3101, tip_amount#3102, tolls_amount#3103, improvement_surcharge#3104, total_amount#3105, congestion_surcharge#3106, airport_fee#3107, PULocationID#3108, DOLocationID#3109, year#3110, month#3111]\n",
      "\n",
      "(3) Filter [codegen id : 1]\n",
      "Input [17]: [pickup_ts#3095, dropoff_ts#3096, trip_minutes#3097L, passenger_count#3098, trip_distance#3099, payment_type#3100, fare_amount#3101, tip_amount#3102, tolls_amount#3103, improvement_surcharge#3104, total_amount#3105, congestion_surcharge#3106, airport_fee#3107, PULocationID#3108, DOLocationID#3109, year#3110, month#3111]\n",
      "Condition : (((((((((((isnotnull(trip_distance#3099) AND isnotnull(fare_amount#3101)) AND isnotnull(trip_minutes#3097L)) AND isnotnull(passenger_count#3098)) AND (trip_distance#3099 > 0.0)) AND (fare_amount#3101 > 0.0)) AND (trip_minutes#3097L > 0)) AND (trip_minutes#3097L < 360)) AND (passenger_count#3098 >= 1)) AND (passenger_count#3098 <= 6)) AND CASE WHEN ((cast(trip_minutes#3097L as double) / 60.0) > 0.0) THEN ((trip_distance#3099 / (cast(trip_minutes#3097L as double) / 60.0)) >= 1.0) END) AND CASE WHEN ((cast(trip_minutes#3097L as double) / 60.0) > 0.0) THEN ((trip_distance#3099 / (cast(trip_minutes#3097L as double) / 60.0)) <= 80.0) END)\n",
      "\n",
      "(4) Project [codegen id : 1]\n",
      "Output [18]: [pickup_ts#3095, dropoff_ts#3096, trip_minutes#3097L, passenger_count#3098, trip_distance#3099, payment_type#3100, fare_amount#3101, tip_amount#3102, tolls_amount#3103, improvement_surcharge#3104, total_amount#3105, congestion_surcharge#3106, airport_fee#3107, PULocationID#3108, DOLocationID#3109, year#3110, month#3111, (cast(trip_minutes#3097L as double) / 60.0) AS trip_hours#3113]\n",
      "Input [17]: [pickup_ts#3095, dropoff_ts#3096, trip_minutes#3097L, passenger_count#3098, trip_distance#3099, payment_type#3100, fare_amount#3101, tip_amount#3102, tolls_amount#3103, improvement_surcharge#3104, total_amount#3105, congestion_surcharge#3106, airport_fee#3107, PULocationID#3108, DOLocationID#3109, year#3110, month#3111]\n",
      "\n",
      "(5) Project [codegen id : 1]\n",
      "Output [20]: [pickup_ts#3095, dropoff_ts#3096, trip_minutes#3097L, passenger_count#3098, trip_distance#3099, payment_type#3100, fare_amount#3101, tip_amount#3102, tolls_amount#3103, improvement_surcharge#3104, total_amount#3105, congestion_surcharge#3106, airport_fee#3107, PULocationID#3108, DOLocationID#3109, year#3110, month#3111, trip_hours#3113, CASE WHEN (trip_hours#3113 > 0.0) THEN (trip_distance#3099 / trip_hours#3113) END AS avg_mph#3114, CASE WHEN (fare_amount#3101 > 0.0) THEN (tip_amount#3102 / fare_amount#3101) END AS tip_rate#3115]\n",
      "Input [18]: [pickup_ts#3095, dropoff_ts#3096, trip_minutes#3097L, passenger_count#3098, trip_distance#3099, payment_type#3100, fare_amount#3101, tip_amount#3102, tolls_amount#3103, improvement_surcharge#3104, total_amount#3105, congestion_surcharge#3106, airport_fee#3107, PULocationID#3108, DOLocationID#3109, year#3110, month#3111, trip_hours#3113]\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import col, when\n",
    "\n",
    "bronze_path = \"../data/processed/yellow_bronze.parquet\"\n",
    "\n",
    "bronze = (\n",
    "    spark.read.parquet(bronze_path)\n",
    "    .where(col(\"year\").cast(\"string\").isin(\"2019\",\"2024\"))\n",
    "    .where(col(\"month\").cast(\"string\").isin(\"01\",\"02\",\"03\"))\n",
    "    .select(\n",
    "        \"pickup_ts\",\"dropoff_ts\",\"trip_minutes\",\"passenger_count\",\"trip_distance\",\n",
    "        \"payment_type\",\"fare_amount\",\"tip_amount\",\"tolls_amount\",\"improvement_surcharge\",\n",
    "        \"total_amount\",\"congestion_surcharge\",\"airport_fee\",\"PULocationID\",\"DOLocationID\",\n",
    "        \"year\",\"month\"\n",
    "    )\n",
    ")\n",
    "\n",
    "df = (\n",
    "    bronze\n",
    "    .withColumn(\"trip_hours\",  col(\"trip_minutes\") / 60.0)\n",
    "    .withColumn(\"avg_mph\",     when(col(\"trip_hours\") > 0, col(\"trip_distance\")/col(\"trip_hours\")))\n",
    "    .withColumn(\"tip_rate\",    when(col(\"fare_amount\") > 0, col(\"tip_amount\")/col(\"fare_amount\")))\n",
    ")\n",
    "\n",
    "\n",
    "df_f = (\n",
    "    df\n",
    "    .filter((col(\"trip_distance\") > 0) & (col(\"fare_amount\") > 0))\n",
    "    .filter((col(\"trip_minutes\")  > 0) & (col(\"trip_minutes\") < 360))    \n",
    "    .filter((col(\"passenger_count\") >= 1) & (col(\"passenger_count\") <= 6))\n",
    "    .filter((col(\"avg_mph\") >= 1) & (col(\"avg_mph\") <= 80))              \n",
    ")\n",
    "\n",
    "df_f.limit(5).show(truncate=False)\n",
    "df_f.explain(\"formatted\")  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-----+------------+-----+--------+------------+-------+-----+\n",
      "|year|month|payment_type|trips|avg_dist|avg_tip_rate|revenue|tolls|\n",
      "+----+-----+------------+-----+--------+------------+-------+-----+\n",
      "+----+-----+------------+-----+--------+------------+-------+-----+\n",
      "\n",
      "== Physical Plan ==\n",
      "AdaptiveSparkPlan (9)\n",
      "+- Sort (8)\n",
      "   +- Exchange (7)\n",
      "      +- HashAggregate (6)\n",
      "         +- Exchange (5)\n",
      "            +- HashAggregate (4)\n",
      "               +- Project (3)\n",
      "                  +- Filter (2)\n",
      "                     +- Scan parquet  (1)\n",
      "\n",
      "\n",
      "(1) Scan parquet \n",
      "Output [10]: [trip_minutes#3097L, passenger_count#3098, trip_distance#3099, payment_type#3100, fare_amount#3101, tip_amount#3102, tolls_amount#3103, total_amount#3105, year#3110, month#3111]\n",
      "Batched: true\n",
      "Location: InMemoryFileIndex [file:/Users/patrickzhu/Desktop/pyspark_pipeline_project/data/processed/yellow_bronze.parquet]\n",
      "PartitionFilters: [cast(year#3110 as string) IN (2019,2024), cast(month#3111 as string) IN (01,02,03)]\n",
      "PushedFilters: [IsNotNull(trip_distance), IsNotNull(fare_amount), IsNotNull(trip_minutes), IsNotNull(passenger_count), GreaterThan(trip_distance,0.0), GreaterThan(fare_amount,0.0), GreaterThan(trip_minutes,0), LessThan(trip_minutes,360), GreaterThanOrEqual(passenger_count,1), LessThanOrEqual(passenger_count,6)]\n",
      "ReadSchema: struct<trip_minutes:bigint,passenger_count:int,trip_distance:double,payment_type:int,fare_amount:double,tip_amount:double,tolls_amount:double,total_amount:double>\n",
      "\n",
      "(2) Filter\n",
      "Input [10]: [trip_minutes#3097L, passenger_count#3098, trip_distance#3099, payment_type#3100, fare_amount#3101, tip_amount#3102, tolls_amount#3103, total_amount#3105, year#3110, month#3111]\n",
      "Condition : (((((((((((isnotnull(trip_distance#3099) AND isnotnull(fare_amount#3101)) AND isnotnull(trip_minutes#3097L)) AND isnotnull(passenger_count#3098)) AND (trip_distance#3099 > 0.0)) AND (fare_amount#3101 > 0.0)) AND (trip_minutes#3097L > 0)) AND (trip_minutes#3097L < 360)) AND (passenger_count#3098 >= 1)) AND (passenger_count#3098 <= 6)) AND CASE WHEN ((cast(trip_minutes#3097L as double) / 60.0) > 0.0) THEN ((trip_distance#3099 / (cast(trip_minutes#3097L as double) / 60.0)) >= 1.0) END) AND CASE WHEN ((cast(trip_minutes#3097L as double) / 60.0) > 0.0) THEN ((trip_distance#3099 / (cast(trip_minutes#3097L as double) / 60.0)) <= 80.0) END)\n",
      "\n",
      "(3) Project\n",
      "Output [7]: [trip_distance#3099, payment_type#3100, tolls_amount#3103, total_amount#3105, year#3110, month#3111, CASE WHEN (fare_amount#3101 > 0.0) THEN (tip_amount#3102 / fare_amount#3101) END AS tip_rate#3115]\n",
      "Input [10]: [trip_minutes#3097L, passenger_count#3098, trip_distance#3099, payment_type#3100, fare_amount#3101, tip_amount#3102, tolls_amount#3103, total_amount#3105, year#3110, month#3111]\n",
      "\n",
      "(4) HashAggregate\n",
      "Input [7]: [trip_distance#3099, payment_type#3100, tolls_amount#3103, total_amount#3105, year#3110, month#3111, tip_rate#3115]\n",
      "Keys [3]: [year#3110, month#3111, payment_type#3100]\n",
      "Functions [5]: [partial_count(1), partial_avg(trip_distance#3099), partial_avg(tip_rate#3115), partial_sum(total_amount#3105), partial_sum(tolls_amount#3103)]\n",
      "Aggregate Attributes [7]: [count#3215L, sum#3216, count#3217L, sum#3218, count#3219L, sum#3220, sum#3221]\n",
      "Results [10]: [year#3110, month#3111, payment_type#3100, count#3222L, sum#3223, count#3224L, sum#3225, count#3226L, sum#3227, sum#3228]\n",
      "\n",
      "(5) Exchange\n",
      "Input [10]: [year#3110, month#3111, payment_type#3100, count#3222L, sum#3223, count#3224L, sum#3225, count#3226L, sum#3227, sum#3228]\n",
      "Arguments: hashpartitioning(year#3110, month#3111, payment_type#3100, 24), ENSURE_REQUIREMENTS, [plan_id=1829]\n",
      "\n",
      "(6) HashAggregate\n",
      "Input [10]: [year#3110, month#3111, payment_type#3100, count#3222L, sum#3223, count#3224L, sum#3225, count#3226L, sum#3227, sum#3228]\n",
      "Keys [3]: [year#3110, month#3111, payment_type#3100]\n",
      "Functions [5]: [count(1), avg(trip_distance#3099), avg(tip_rate#3115), sum(total_amount#3105), sum(tolls_amount#3103)]\n",
      "Aggregate Attributes [5]: [count(1)#3202L, avg(trip_distance#3099)#3203, avg(tip_rate#3115)#3204, sum(total_amount#3105)#3205, sum(tolls_amount#3103)#3206]\n",
      "Results [8]: [year#3110, month#3111, payment_type#3100, count(1)#3202L AS trips#3177L, avg(trip_distance#3099)#3203 AS avg_dist#3178, avg(tip_rate#3115)#3204 AS avg_tip_rate#3179, sum(total_amount#3105)#3205 AS revenue#3180, sum(tolls_amount#3103)#3206 AS tolls#3181]\n",
      "\n",
      "(7) Exchange\n",
      "Input [8]: [year#3110, month#3111, payment_type#3100, trips#3177L, avg_dist#3178, avg_tip_rate#3179, revenue#3180, tolls#3181]\n",
      "Arguments: rangepartitioning(year#3110 ASC NULLS FIRST, month#3111 ASC NULLS FIRST, payment_type#3100 ASC NULLS FIRST, 24), ENSURE_REQUIREMENTS, [plan_id=1832]\n",
      "\n",
      "(8) Sort\n",
      "Input [8]: [year#3110, month#3111, payment_type#3100, trips#3177L, avg_dist#3178, avg_tip_rate#3179, revenue#3180, tolls#3181]\n",
      "Arguments: [year#3110 ASC NULLS FIRST, month#3111 ASC NULLS FIRST, payment_type#3100 ASC NULLS FIRST], true, 0\n",
      "\n",
      "(9) AdaptiveSparkPlan\n",
      "Output [8]: [year#3110, month#3111, payment_type#3100, trips#3177L, avg_dist#3178, avg_tip_rate#3179, revenue#3180, tolls#3181]\n",
      "Arguments: isFinalPlan=false\n",
      "\n",
      "\n",
      "+----+-----+--------+--------+---------------+\n",
      "|year|month|p50_dist|p95_dist|unique_od_pairs|\n",
      "+----+-----+--------+--------+---------------+\n",
      "+----+-----+--------+--------+---------------+\n",
      "\n",
      "== Physical Plan ==\n",
      "AdaptiveSparkPlan (9)\n",
      "+- Sort (8)\n",
      "   +- Exchange (7)\n",
      "      +- ObjectHashAggregate (6)\n",
      "         +- Exchange (5)\n",
      "            +- ObjectHashAggregate (4)\n",
      "               +- Project (3)\n",
      "                  +- Filter (2)\n",
      "                     +- Scan parquet  (1)\n",
      "\n",
      "\n",
      "(1) Scan parquet \n",
      "Output [8]: [trip_minutes#3097L, passenger_count#3098, trip_distance#3099, fare_amount#3101, PULocationID#3108, DOLocationID#3109, year#3110, month#3111]\n",
      "Batched: true\n",
      "Location: InMemoryFileIndex [file:/Users/patrickzhu/Desktop/pyspark_pipeline_project/data/processed/yellow_bronze.parquet]\n",
      "PartitionFilters: [cast(year#3110 as string) IN (2019,2024), cast(month#3111 as string) IN (01,02,03)]\n",
      "PushedFilters: [IsNotNull(trip_distance), IsNotNull(fare_amount), IsNotNull(trip_minutes), IsNotNull(passenger_count), GreaterThan(trip_distance,0.0), GreaterThan(fare_amount,0.0), GreaterThan(trip_minutes,0), LessThan(trip_minutes,360), GreaterThanOrEqual(passenger_count,1), LessThanOrEqual(passenger_count,6)]\n",
      "ReadSchema: struct<trip_minutes:bigint,passenger_count:int,trip_distance:double,fare_amount:double,PULocationID:int,DOLocationID:int>\n",
      "\n",
      "(2) Filter\n",
      "Input [8]: [trip_minutes#3097L, passenger_count#3098, trip_distance#3099, fare_amount#3101, PULocationID#3108, DOLocationID#3109, year#3110, month#3111]\n",
      "Condition : (((((((((((isnotnull(trip_distance#3099) AND isnotnull(fare_amount#3101)) AND isnotnull(trip_minutes#3097L)) AND isnotnull(passenger_count#3098)) AND (trip_distance#3099 > 0.0)) AND (fare_amount#3101 > 0.0)) AND (trip_minutes#3097L > 0)) AND (trip_minutes#3097L < 360)) AND (passenger_count#3098 >= 1)) AND (passenger_count#3098 <= 6)) AND CASE WHEN ((cast(trip_minutes#3097L as double) / 60.0) > 0.0) THEN ((trip_distance#3099 / (cast(trip_minutes#3097L as double) / 60.0)) >= 1.0) END) AND CASE WHEN ((cast(trip_minutes#3097L as double) / 60.0) > 0.0) THEN ((trip_distance#3099 / (cast(trip_minutes#3097L as double) / 60.0)) <= 80.0) END)\n",
      "\n",
      "(3) Project\n",
      "Output [5]: [trip_distance#3099, PULocationID#3108, DOLocationID#3109, year#3110, month#3111]\n",
      "Input [8]: [trip_minutes#3097L, passenger_count#3098, trip_distance#3099, fare_amount#3101, PULocationID#3108, DOLocationID#3109, year#3110, month#3111]\n",
      "\n",
      "(4) ObjectHashAggregate\n",
      "Input [5]: [trip_distance#3099, PULocationID#3108, DOLocationID#3109, year#3110, month#3111]\n",
      "Keys [2]: [year#3110, month#3111]\n",
      "Functions [3]: [partial_percentile_approx(trip_distance#3099, 0.5, 1000, 0, 0), partial_percentile_approx(trip_distance#3099, 0.95, 1000, 0, 0), partial_approx_count_distinct(struct(PULocationID, PULocationID#3108, DOLocationID, DOLocationID#3109), 0.05, 0, 0)]\n",
      "Aggregate Attributes [54]: [buf#3932, buf#3933, MS[0]#3283L, MS[1]#3284L, MS[2]#3285L, MS[3]#3286L, MS[4]#3287L, MS[5]#3288L, MS[6]#3289L, MS[7]#3290L, MS[8]#3291L, MS[9]#3292L, MS[10]#3293L, MS[11]#3294L, MS[12]#3295L, MS[13]#3296L, MS[14]#3297L, MS[15]#3298L, MS[16]#3299L, MS[17]#3300L, MS[18]#3301L, MS[19]#3302L, MS[20]#3303L, MS[21]#3304L, MS[22]#3305L, MS[23]#3306L, MS[24]#3307L, MS[25]#3308L, MS[26]#3309L, MS[27]#3310L, MS[28]#3311L, MS[29]#3312L, MS[30]#3313L, MS[31]#3314L, MS[32]#3315L, MS[33]#3316L, MS[34]#3317L, MS[35]#3318L, MS[36]#3319L, MS[37]#3320L, MS[38]#3321L, MS[39]#3322L, MS[40]#3323L, MS[41]#3324L, MS[42]#3325L, MS[43]#3326L, MS[44]#3327L, MS[45]#3328L, MS[46]#3329L, MS[47]#3330L, MS[48]#3331L, MS[49]#3332L, MS[50]#3333L, MS[51]#3334L]\n",
      "Results [56]: [year#3110, month#3111, buf#3934, buf#3935, MS[0]#3335L, MS[1]#3336L, MS[2]#3337L, MS[3]#3338L, MS[4]#3339L, MS[5]#3340L, MS[6]#3341L, MS[7]#3342L, MS[8]#3343L, MS[9]#3344L, MS[10]#3345L, MS[11]#3346L, MS[12]#3347L, MS[13]#3348L, MS[14]#3349L, MS[15]#3350L, MS[16]#3351L, MS[17]#3352L, MS[18]#3353L, MS[19]#3354L, MS[20]#3355L, MS[21]#3356L, MS[22]#3357L, MS[23]#3358L, MS[24]#3359L, MS[25]#3360L, MS[26]#3361L, MS[27]#3362L, MS[28]#3363L, MS[29]#3364L, MS[30]#3365L, MS[31]#3366L, MS[32]#3367L, MS[33]#3368L, MS[34]#3369L, MS[35]#3370L, MS[36]#3371L, MS[37]#3372L, MS[38]#3373L, MS[39]#3374L, MS[40]#3375L, MS[41]#3376L, MS[42]#3377L, MS[43]#3378L, MS[44]#3379L, MS[45]#3380L, MS[46]#3381L, MS[47]#3382L, MS[48]#3383L, MS[49]#3384L, MS[50]#3385L, MS[51]#3386L]\n",
      "\n",
      "(5) Exchange\n",
      "Input [56]: [year#3110, month#3111, buf#3934, buf#3935, MS[0]#3335L, MS[1]#3336L, MS[2]#3337L, MS[3]#3338L, MS[4]#3339L, MS[5]#3340L, MS[6]#3341L, MS[7]#3342L, MS[8]#3343L, MS[9]#3344L, MS[10]#3345L, MS[11]#3346L, MS[12]#3347L, MS[13]#3348L, MS[14]#3349L, MS[15]#3350L, MS[16]#3351L, MS[17]#3352L, MS[18]#3353L, MS[19]#3354L, MS[20]#3355L, MS[21]#3356L, MS[22]#3357L, MS[23]#3358L, MS[24]#3359L, MS[25]#3360L, MS[26]#3361L, MS[27]#3362L, MS[28]#3363L, MS[29]#3364L, MS[30]#3365L, MS[31]#3366L, MS[32]#3367L, MS[33]#3368L, MS[34]#3369L, MS[35]#3370L, MS[36]#3371L, MS[37]#3372L, MS[38]#3373L, MS[39]#3374L, MS[40]#3375L, MS[41]#3376L, MS[42]#3377L, MS[43]#3378L, MS[44]#3379L, MS[45]#3380L, MS[46]#3381L, MS[47]#3382L, MS[48]#3383L, MS[49]#3384L, MS[50]#3385L, MS[51]#3386L]\n",
      "Arguments: hashpartitioning(year#3110, month#3111, 24), ENSURE_REQUIREMENTS, [plan_id=1912]\n",
      "\n",
      "(6) ObjectHashAggregate\n",
      "Input [56]: [year#3110, month#3111, buf#3934, buf#3935, MS[0]#3335L, MS[1]#3336L, MS[2]#3337L, MS[3]#3338L, MS[4]#3339L, MS[5]#3340L, MS[6]#3341L, MS[7]#3342L, MS[8]#3343L, MS[9]#3344L, MS[10]#3345L, MS[11]#3346L, MS[12]#3347L, MS[13]#3348L, MS[14]#3349L, MS[15]#3350L, MS[16]#3351L, MS[17]#3352L, MS[18]#3353L, MS[19]#3354L, MS[20]#3355L, MS[21]#3356L, MS[22]#3357L, MS[23]#3358L, MS[24]#3359L, MS[25]#3360L, MS[26]#3361L, MS[27]#3362L, MS[28]#3363L, MS[29]#3364L, MS[30]#3365L, MS[31]#3366L, MS[32]#3367L, MS[33]#3368L, MS[34]#3369L, MS[35]#3370L, MS[36]#3371L, MS[37]#3372L, MS[38]#3373L, MS[39]#3374L, MS[40]#3375L, MS[41]#3376L, MS[42]#3377L, MS[43]#3378L, MS[44]#3379L, MS[45]#3380L, MS[46]#3381L, MS[47]#3382L, MS[48]#3383L, MS[49]#3384L, MS[50]#3385L, MS[51]#3386L]\n",
      "Keys [2]: [year#3110, month#3111]\n",
      "Functions [3]: [percentile_approx(trip_distance#3099, 0.5, 1000, 0, 0), percentile_approx(trip_distance#3099, 0.95, 1000, 0, 0), approx_count_distinct(struct(PULocationID, PULocationID#3108, DOLocationID, DOLocationID#3109), 0.05, 0, 0)]\n",
      "Aggregate Attributes [3]: [percentile_approx(trip_distance#3099, 0.5, 1000, 0, 0)#3281, percentile_approx(trip_distance#3099, 0.95, 1000, 0, 0)#3282, approx_count_distinct(struct(PULocationID, PULocationID#3108, DOLocationID, DOLocationID#3109), 0.05, 0, 0)#3387L]\n",
      "Results [5]: [year#3110, month#3111, percentile_approx(trip_distance#3099, 0.5, 1000, 0, 0)#3281 AS p50_dist#3258, percentile_approx(trip_distance#3099, 0.95, 1000, 0, 0)#3282 AS p95_dist#3259, approx_count_distinct(struct(PULocationID, PULocationID#3108, DOLocationID, DOLocationID#3109), 0.05, 0, 0)#3387L AS unique_od_pairs#3260L]\n",
      "\n",
      "(7) Exchange\n",
      "Input [5]: [year#3110, month#3111, p50_dist#3258, p95_dist#3259, unique_od_pairs#3260L]\n",
      "Arguments: rangepartitioning(year#3110 ASC NULLS FIRST, month#3111 ASC NULLS FIRST, 24), ENSURE_REQUIREMENTS, [plan_id=1915]\n",
      "\n",
      "(8) Sort\n",
      "Input [5]: [year#3110, month#3111, p50_dist#3258, p95_dist#3259, unique_od_pairs#3260L]\n",
      "Arguments: [year#3110 ASC NULLS FIRST, month#3111 ASC NULLS FIRST], true, 0\n",
      "\n",
      "(9) AdaptiveSparkPlan\n",
      "Output [5]: [year#3110, month#3111, p50_dist#3258, p95_dist#3259, unique_od_pairs#3260L]\n",
      "Arguments: isFinalPlan=false\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import functions as F\n",
    "\n",
    "monthly_kpi = (\n",
    "    df_f.groupBy(\"year\",\"month\",\"payment_type\")\n",
    "        .agg(\n",
    "            F.count(\"*\").alias(\"trips\"),\n",
    "            F.avg(\"trip_distance\").alias(\"avg_dist\"),\n",
    "            F.avg(\"tip_rate\").alias(\"avg_tip_rate\"),\n",
    "            F.sum(\"total_amount\").alias(\"revenue\"),\n",
    "            F.sum(\"tolls_amount\").alias(\"tolls\")\n",
    "        )\n",
    "        .orderBy(\"year\",\"month\",\"payment_type\")\n",
    ")\n",
    "\n",
    "monthly_kpi.show(12, truncate=False)  \n",
    "monthly_kpi.explain(\"formatted\")      \n",
    "\n",
    "dist_quantiles = (\n",
    "    df_f.groupBy(\"year\",\"month\")\n",
    "        .agg(\n",
    "            F.expr(\"percentile_approx(trip_distance, 0.5, 1000)\").alias(\"p50_dist\"),\n",
    "            F.expr(\"percentile_approx(trip_distance, 0.95, 1000)\").alias(\"p95_dist\"),\n",
    "            F.approx_count_distinct(F.struct(\"PULocationID\",\"DOLocationID\")).alias(\"unique_od_pairs\")\n",
    "        )\n",
    "        .orderBy(\"year\",\"month\")\n",
    ")\n",
    "\n",
    "dist_quantiles.show(truncate=False)\n",
    "dist_quantiles.explain(\"formatted\")   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-----+------------+-----+------------+-------------+\n",
      "|year|month|payment_type|trips|avg_tip_rate|avg_speed_mph|\n",
      "+----+-----+------------+-----+------------+-------------+\n",
      "+----+-----+------------+-----+------------+-------------+\n",
      "\n",
      "== Physical Plan ==\n",
      "AdaptiveSparkPlan (10)\n",
      "+- Sort (9)\n",
      "   +- Exchange (8)\n",
      "      +- HashAggregate (7)\n",
      "         +- Exchange (6)\n",
      "            +- HashAggregate (5)\n",
      "               +- Project (4)\n",
      "                  +- Project (3)\n",
      "                     +- Filter (2)\n",
      "                        +- Scan parquet  (1)\n",
      "\n",
      "\n",
      "(1) Scan parquet \n",
      "Output [8]: [trip_minutes#3097L, passenger_count#3098, trip_distance#3099, payment_type#3100, fare_amount#3101, tip_amount#3102, year#3110, month#3111]\n",
      "Batched: true\n",
      "Location: InMemoryFileIndex [file:/Users/patrickzhu/Desktop/pyspark_pipeline_project/data/processed/yellow_bronze.parquet]\n",
      "PartitionFilters: [cast(year#3110 as string) IN (2019,2024), cast(month#3111 as string) IN (01,02,03)]\n",
      "PushedFilters: [IsNotNull(trip_distance), IsNotNull(fare_amount), IsNotNull(trip_minutes), IsNotNull(passenger_count), GreaterThan(trip_distance,0.0), GreaterThan(fare_amount,0.0), GreaterThan(trip_minutes,0), LessThan(trip_minutes,360), GreaterThanOrEqual(passenger_count,1), LessThanOrEqual(passenger_count,6)]\n",
      "ReadSchema: struct<trip_minutes:bigint,passenger_count:int,trip_distance:double,payment_type:int,fare_amount:double,tip_amount:double>\n",
      "\n",
      "(2) Filter\n",
      "Input [8]: [trip_minutes#3097L, passenger_count#3098, trip_distance#3099, payment_type#3100, fare_amount#3101, tip_amount#3102, year#3110, month#3111]\n",
      "Condition : (((((((((((isnotnull(trip_distance#3099) AND isnotnull(fare_amount#3101)) AND isnotnull(trip_minutes#3097L)) AND isnotnull(passenger_count#3098)) AND (trip_distance#3099 > 0.0)) AND (fare_amount#3101 > 0.0)) AND (trip_minutes#3097L > 0)) AND (trip_minutes#3097L < 360)) AND (passenger_count#3098 >= 1)) AND (passenger_count#3098 <= 6)) AND CASE WHEN ((cast(trip_minutes#3097L as double) / 60.0) > 0.0) THEN ((trip_distance#3099 / (cast(trip_minutes#3097L as double) / 60.0)) >= 1.0) END) AND CASE WHEN ((cast(trip_minutes#3097L as double) / 60.0) > 0.0) THEN ((trip_distance#3099 / (cast(trip_minutes#3097L as double) / 60.0)) <= 80.0) END)\n",
      "\n",
      "(3) Project\n",
      "Output [7]: [trip_distance#3099, payment_type#3100, fare_amount#3101, tip_amount#3102, year#3110, month#3111, (cast(trip_minutes#3097L as double) / 60.0) AS trip_hours#3113]\n",
      "Input [8]: [trip_minutes#3097L, passenger_count#3098, trip_distance#3099, payment_type#3100, fare_amount#3101, tip_amount#3102, year#3110, month#3111]\n",
      "\n",
      "(4) Project\n",
      "Output [5]: [payment_type#3100, year#3110, month#3111, CASE WHEN (trip_hours#3113 > 0.0) THEN (trip_distance#3099 / trip_hours#3113) END AS avg_mph#3114, CASE WHEN (fare_amount#3101 > 0.0) THEN (tip_amount#3102 / fare_amount#3101) END AS tip_rate#3115]\n",
      "Input [7]: [trip_distance#3099, payment_type#3100, fare_amount#3101, tip_amount#3102, year#3110, month#3111, trip_hours#3113]\n",
      "\n",
      "(5) HashAggregate\n",
      "Input [5]: [payment_type#3100, year#3110, month#3111, avg_mph#3114, tip_rate#3115]\n",
      "Keys [3]: [year#3110, month#3111, payment_type#3100]\n",
      "Functions [3]: [partial_count(1), partial_avg(tip_rate#3115), partial_avg(avg_mph#3114)]\n",
      "Aggregate Attributes [5]: [count#3948L, sum#3949, count#3950L, sum#3951, count#3952L]\n",
      "Results [8]: [year#3110, month#3111, payment_type#3100, count#3953L, sum#3954, count#3955L, sum#3956, count#3957L]\n",
      "\n",
      "(6) Exchange\n",
      "Input [8]: [year#3110, month#3111, payment_type#3100, count#3953L, sum#3954, count#3955L, sum#3956, count#3957L]\n",
      "Arguments: hashpartitioning(year#3110, month#3111, payment_type#3100, 24), ENSURE_REQUIREMENTS, [plan_id=2012]\n",
      "\n",
      "(7) HashAggregate\n",
      "Input [8]: [year#3110, month#3111, payment_type#3100, count#3953L, sum#3954, count#3955L, sum#3956, count#3957L]\n",
      "Keys [3]: [year#3110, month#3111, payment_type#3100]\n",
      "Functions [3]: [count(1), avg(tip_rate#3115), avg(avg_mph#3114)]\n",
      "Aggregate Attributes [3]: [count(1)#3939L, avg(tip_rate#3115)#3940, avg(avg_mph#3114)#3941]\n",
      "Results [6]: [year#3110, month#3111, payment_type#3100, count(1)#3939L AS trips#3936L, round(avg(tip_rate#3115)#3940, 3) AS avg_tip_rate#3937, round(avg(avg_mph#3114)#3941, 2) AS avg_speed_mph#3938]\n",
      "\n",
      "(8) Exchange\n",
      "Input [6]: [year#3110, month#3111, payment_type#3100, trips#3936L, avg_tip_rate#3937, avg_speed_mph#3938]\n",
      "Arguments: rangepartitioning(year#3110 ASC NULLS FIRST, month#3111 ASC NULLS FIRST, payment_type#3100 ASC NULLS FIRST, 24), ENSURE_REQUIREMENTS, [plan_id=2015]\n",
      "\n",
      "(9) Sort\n",
      "Input [6]: [year#3110, month#3111, payment_type#3100, trips#3936L, avg_tip_rate#3937, avg_speed_mph#3938]\n",
      "Arguments: [year#3110 ASC NULLS FIRST, month#3111 ASC NULLS FIRST, payment_type#3100 ASC NULLS FIRST], true, 0\n",
      "\n",
      "(10) AdaptiveSparkPlan\n",
      "Output [6]: [year#3110, month#3111, payment_type#3100, trips#3936L, avg_tip_rate#3937, avg_speed_mph#3938]\n",
      "Arguments: isFinalPlan=false\n",
      "\n",
      "\n",
      "+----+-----+------------+------------+-----+\n",
      "|year|month|PULocationID|DOLocationID|trips|\n",
      "+----+-----+------------+------------+-----+\n",
      "+----+-----+------------+------------+-----+\n",
      "\n",
      "== Physical Plan ==\n",
      "AdaptiveSparkPlan (8)\n",
      "+- TakeOrderedAndProject (7)\n",
      "   +- HashAggregate (6)\n",
      "      +- Exchange (5)\n",
      "         +- HashAggregate (4)\n",
      "            +- Project (3)\n",
      "               +- Filter (2)\n",
      "                  +- Scan parquet  (1)\n",
      "\n",
      "\n",
      "(1) Scan parquet \n",
      "Output [8]: [trip_minutes#3097L, passenger_count#3098, trip_distance#3099, fare_amount#3101, PULocationID#3108, DOLocationID#3109, year#3110, month#3111]\n",
      "Batched: true\n",
      "Location: InMemoryFileIndex [file:/Users/patrickzhu/Desktop/pyspark_pipeline_project/data/processed/yellow_bronze.parquet]\n",
      "PartitionFilters: [cast(year#3110 as string) IN (2019,2024), cast(month#3111 as string) IN (01,02,03)]\n",
      "PushedFilters: [IsNotNull(trip_distance), IsNotNull(fare_amount), IsNotNull(trip_minutes), IsNotNull(passenger_count), GreaterThan(trip_distance,0.0), GreaterThan(fare_amount,0.0), GreaterThan(trip_minutes,0), LessThan(trip_minutes,360), GreaterThanOrEqual(passenger_count,1), LessThanOrEqual(passenger_count,6)]\n",
      "ReadSchema: struct<trip_minutes:bigint,passenger_count:int,trip_distance:double,fare_amount:double,PULocationID:int,DOLocationID:int>\n",
      "\n",
      "(2) Filter\n",
      "Input [8]: [trip_minutes#3097L, passenger_count#3098, trip_distance#3099, fare_amount#3101, PULocationID#3108, DOLocationID#3109, year#3110, month#3111]\n",
      "Condition : (((((((((((isnotnull(trip_distance#3099) AND isnotnull(fare_amount#3101)) AND isnotnull(trip_minutes#3097L)) AND isnotnull(passenger_count#3098)) AND (trip_distance#3099 > 0.0)) AND (fare_amount#3101 > 0.0)) AND (trip_minutes#3097L > 0)) AND (trip_minutes#3097L < 360)) AND (passenger_count#3098 >= 1)) AND (passenger_count#3098 <= 6)) AND CASE WHEN ((cast(trip_minutes#3097L as double) / 60.0) > 0.0) THEN ((trip_distance#3099 / (cast(trip_minutes#3097L as double) / 60.0)) >= 1.0) END) AND CASE WHEN ((cast(trip_minutes#3097L as double) / 60.0) > 0.0) THEN ((trip_distance#3099 / (cast(trip_minutes#3097L as double) / 60.0)) <= 80.0) END)\n",
      "\n",
      "(3) Project\n",
      "Output [4]: [PULocationID#3108, DOLocationID#3109, year#3110, month#3111]\n",
      "Input [8]: [trip_minutes#3097L, passenger_count#3098, trip_distance#3099, fare_amount#3101, PULocationID#3108, DOLocationID#3109, year#3110, month#3111]\n",
      "\n",
      "(4) HashAggregate\n",
      "Input [4]: [PULocationID#3108, DOLocationID#3109, year#3110, month#3111]\n",
      "Keys [4]: [year#3110, month#3111, PULocationID#3108, DOLocationID#3109]\n",
      "Functions [1]: [partial_count(1)]\n",
      "Aggregate Attributes [1]: [count#3986L]\n",
      "Results [5]: [year#3110, month#3111, PULocationID#3108, DOLocationID#3109, count#3987L]\n",
      "\n",
      "(5) Exchange\n",
      "Input [5]: [year#3110, month#3111, PULocationID#3108, DOLocationID#3109, count#3987L]\n",
      "Arguments: hashpartitioning(year#3110, month#3111, PULocationID#3108, DOLocationID#3109, 24), ENSURE_REQUIREMENTS, [plan_id=2094]\n",
      "\n",
      "(6) HashAggregate\n",
      "Input [5]: [year#3110, month#3111, PULocationID#3108, DOLocationID#3109, count#3987L]\n",
      "Keys [4]: [year#3110, month#3111, PULocationID#3108, DOLocationID#3109]\n",
      "Functions [1]: [count(1)]\n",
      "Aggregate Attributes [1]: [count(1)#3980L]\n",
      "Results [5]: [year#3110, month#3111, PULocationID#3108, DOLocationID#3109, count(1)#3980L AS trips#3979L]\n",
      "\n",
      "(7) TakeOrderedAndProject\n",
      "Input [5]: [year#3110, month#3111, PULocationID#3108, DOLocationID#3109, trips#3979L]\n",
      "Arguments: 20, [trips#3979L DESC NULLS LAST], [year#3110, month#3111, PULocationID#3108, DOLocationID#3109, trips#3979L]\n",
      "\n",
      "(8) AdaptiveSparkPlan\n",
      "Output [5]: [year#3110, month#3111, PULocationID#3108, DOLocationID#3109, trips#3979L]\n",
      "Arguments: isFinalPlan=false\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_f.createOrReplaceTempView(\"trips\")\n",
    "\n",
    "sql1 = spark.sql(\"\"\"\n",
    "SELECT year, month, payment_type,\n",
    "       COUNT(*) AS trips,\n",
    "       ROUND(AVG(tip_rate), 3) AS avg_tip_rate,\n",
    "       ROUND(AVG(avg_mph),  2) AS avg_speed_mph\n",
    "FROM trips\n",
    "GROUP BY year, month, payment_type\n",
    "ORDER BY year, month, payment_type\n",
    "\"\"\")\n",
    "sql1.show(truncate=False)\n",
    "sql1.explain(\"formatted\")             \n",
    "\n",
    "\n",
    "sql2 = spark.sql(\"\"\"\n",
    "SELECT year, month, PULocationID, DOLocationID,\n",
    "       COUNT(*) AS trips\n",
    "FROM trips\n",
    "GROUP BY year, month, PULocationID, DOLocationID\n",
    "ORDER BY trips DESC\n",
    "LIMIT 20\n",
    "\"\"\")\n",
    "sql2.show(truncate=False)\n",
    "sql2.explain(\"formatted\")               \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Gold outputs written.\n"
     ]
    }
   ],
   "source": [
    "(\n",
    "    monthly_kpi\n",
    "    .coalesce(1)  \n",
    "    .write.mode(\"overwrite\").option(\"compression\",\"snappy\")\n",
    "    .parquet(\"../data/processed/gold_monthly_kpi.parquet\")\n",
    ")\n",
    "\n",
    "(\n",
    "    dist_quantiles\n",
    "    .coalesce(1)\n",
    "    .write.mode(\"overwrite\").option(\"compression\",\"snappy\")\n",
    "    .parquet(\"../data/processed/gold_dist_quantiles.parquet\")\n",
    ")\n",
    "\n",
    "print(\"✅ Gold outputs written.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First run (no cache): 0.19s\n",
      "Second run (after cache): 0.03s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DataFrame[pickup_ts: timestamp, dropoff_ts: timestamp, trip_minutes: bigint, passenger_count: int, trip_distance: double, payment_type: int, fare_amount: double, tip_amount: double, tolls_amount: double, improvement_surcharge: double, total_amount: double, congestion_surcharge: double, airport_fee: double, PULocationID: int, DOLocationID: int, year: int, month: int, trip_hours: double, avg_mph: double, tip_rate: double]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "df_2019_01 = df_f.filter((col(\"year\")==\"2019\") & (col(\"month\")==\"01\"))\n",
    "\n",
    "\n",
    "t0 = time.perf_counter()\n",
    "_ = (df_2019_01.groupBy(\"payment_type\").agg(F.count(\"*\").alias(\"trips\"),\n",
    "                                            F.avg(\"tip_rate\").alias(\"avg_tip\")).collect())\n",
    "t1 = time.perf_counter()\n",
    "print(f\"First run (no cache): {t1 - t0:.2f}s\")\n",
    "\n",
    "\n",
    "df_2019_01.cache()\n",
    "_ = df_2019_01.count()  \n",
    "\n",
    "t2 = time.perf_counter()\n",
    "_ = (df_2019_01.groupBy(\"payment_type\").agg(F.count(\"*\").alias(\"trips\"),\n",
    "                                            F.avg(\"tip_rate\").alias(\"avg_tip\")).collect())\n",
    "t3 = time.perf_counter()\n",
    "print(f\"Second run (after cache): {t3 - t2:.2f}s\")\n",
    "\n",
    "\n",
    "df_2019_01.unpersist()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count(): 0\n",
      "first(): None\n"
     ]
    }
   ],
   "source": [
    "\n",
    "t_demo = (bronze\n",
    "          .select(\"trip_distance\",\"fare_amount\")\n",
    "          .filter(col(\"trip_distance\") > 0)\n",
    "          .withColumn(\"fare_per_mile\", col(\"fare_amount\")/col(\"trip_distance\")))\n",
    "\n",
    "\n",
    "print(\"count():\", t_demo.count())  \n",
    "print(\"first():\", t_demo.first())  \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
